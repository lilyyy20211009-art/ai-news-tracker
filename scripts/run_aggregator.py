"""
AI News Aggregator - ä¸»è¿è¡Œè„šæœ¬
æ‰§è¡Œå®Œæ•´çš„æ•°æ®èšåˆã€å¤„ç†å’Œè¾“å‡ºæµç¨‹
"""

import os
import sys
import yaml
from pathlib import Path
from datetime import datetime

# æ·»åŠ è„šæœ¬ç›®å½•åˆ°è·¯å¾„
script_dir = Path(__file__).parent
sys.path.insert(0, str(script_dir))

from fetchers import fetch_all_sources
from llm_processor import process_batch, generate_daily_summary
from feishu_output import export_to_json, export_to_markdown, export_to_feishu, export_to_html


def load_config(config_path: str = None) -> dict:
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    if config_path is None:
        # é»˜è®¤æŸ¥æ‰¾å½“å‰ç›®å½•å’Œç”¨æˆ·ç›®å½•ä¸‹çš„ config.yaml
        for path in ["./config.yaml", "~/config.yaml", "~/.claude/skills/ai-news-aggregator/config.yaml"]:
            expanded = Path(path).expanduser()
            if expanded.exists():
                config_path = str(expanded)
                break

    if config_path and Path(config_path).exists():
        with open(config_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)

    # è¿”å›é»˜è®¤é…ç½®
    return {
        "sources": {
            "rss": {"enabled": True, "hours": 24},
            "youtube": {"enabled": False},
            "twitter": {"enabled": False},
            "reddit": {"enabled": False}
        },
        "llm": {
            "api_key": os.getenv("DEEPSEEK_API_KEY", ""),
            "translate": True,
            "summarize": True,
            "categorize": True,
            "filter_by_value": True
        },
        "output": {
            "json": {"enabled": True, "path": "./output/news.json"},
            "markdown": {"enabled": True, "path": "./output/news.md"},
            "feishu": {"enabled": False}
        }
    }


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸ¤– AI News Aggregator")
    print("=" * 60)

    # 1. åŠ è½½é…ç½®
    print("\nğŸ“‹ åŠ è½½é…ç½®...")
    config = load_config()
    print(f"   RSS: {'âœ…' if config['sources']['rss']['enabled'] else 'âŒ'}")
    print(f"   YouTube: {'âœ…' if config['sources'].get('youtube', {}).get('enabled') else 'âŒ'}")
    print(f"   Twitter: {'âœ…' if config['sources'].get('twitter', {}).get('enabled') else 'âŒ'}")

    # 2. è·å–æ•°æ®
    print("\nğŸ” è·å–æ•°æ®...")
    raw_items = fetch_all_sources(config["sources"])
    print(f"   è·å–åˆ° {len(raw_items)} æ¡åŸå§‹å†…å®¹")

    if not raw_items:
        print("   âš ï¸  æœªè·å–åˆ°ä»»ä½•å†…å®¹")
        return

    # 3. LLM å¤„ç†
    llm_config = config.get("llm", {})
    if llm_config.get("api_key") or os.getenv("DEEPSEEK_API_KEY"):
        print("\nğŸ§  LLM å¤„ç†ä¸­...")
        print("   - ç¿»è¯‘: âœ…" if llm_config.get("translate") else "   - ç¿»è¯‘: âŒ")
        print("   - æ‘˜è¦: âœ…" if llm_config.get("summarize") else "   - æ‘˜è¦: âŒ")
        print("   - åˆ†ç±»: âœ…" if llm_config.get("categorize") else "   - åˆ†ç±»: âŒ")

        processed_items = process_batch(raw_items, llm_config)
        print(f"   å¤„ç†å {len(processed_items)} æ¡å†…å®¹")
    else:
        print("\nâš ï¸  æœªé…ç½® DeepSeek API Keyï¼Œè·³è¿‡ LLM å¤„ç†")
        processed_items = raw_items

    # 4. è¾“å‡ºç»“æœ
    print("\nğŸ“¤ è¾“å‡ºç»“æœ...")

    output_config = config.get("output", {})

    # ç”Ÿæˆä¸­æ–‡æ‘˜è¦
    print("\nğŸ“ ç”Ÿæˆä¸­æ–‡æ‘˜è¦...")
    daily_summary = generate_daily_summary(processed_items)

    # JSON
    if output_config.get("json", {}).get("enabled", True):
        json_path = output_config["json"].get("path", "./output/news.json")
        export_to_json(processed_items, json_path)

    # Markdown
    if output_config.get("markdown", {}).get("enabled", True):
        md_path = output_config["markdown"].get("path", "./output/news.md")
        export_to_markdown(processed_items, md_path)

    # HTML (å¸¦ä¸­æ–‡æ‘˜è¦å’Œåˆ·æ–°æŒ‰é’®)
    html_path = output_config.get("html", {}).get("path", "./output/today.html")
    export_to_html(processed_items, daily_summary, html_path)

    # é£ä¹¦
    if output_config.get("feishu", {}).get("enabled", False):
        feishu_config = output_config["feishu"]
        count = export_to_feishu(processed_items, feishu_config)
        print(f"   é£ä¹¦: {count} æ¡è®°å½•")

    print("\nâœ… å®Œæˆ!")
    print(f"   å…±å¤„ç† {len(processed_items)} æ¡å†…å®¹")
    print(f"   HTML æŠ¥å‘Š: {html_path}")
    print("=" * 60)


if __name__ == "__main__":
    main()
